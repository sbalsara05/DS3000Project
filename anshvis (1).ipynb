{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DS 3000 HW 5 \n",
    "\n",
    "Due: Sunday July 20th @ 11:59 PM EST\n",
    "\n",
    "### Submission Instructions\n",
    "Submit this `ipynb` file and the a `PDF` file included with the coding results to Gradescope (this can also be done via the assignment on Canvas).  To ensure that your submitted files represent your latest code, make sure to give a fresh `Kernel > Restart & Run All` just before uploading the files to gradescope. \n",
    "\n",
    "**Notice that this is a group assignment. Each group only need to submit one copy and when you submit the work, please include everyone in your group.**\n",
    "\n",
    "### Tips for success\n",
    "- Start early\n",
    "- Make use of Piazza\n",
    "- Make use of Office hour\n",
    "- Remember to use cells and headings to make the notebook easy to read (if a grader cannot find the answer to a problem, you will receive no points for it)\n",
    "- Under no circumstances may one student view or share their ungraded homework or quiz with another student [(see also)](http://www.northeastern.edu/osccr/academic-integrity), though you are welcome to **talk about** (not show each other) the problems."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Project proposal\n",
    "\n",
    "For this course, we aim to complete a data analysis project about the the game [Palworld](https://en.wikipedia.org/wiki/Palworld). To help you start with the project, here are a couple of things you need to consider and work on to get a clean data for later analysis. \n",
    "\n",
    "To start with the project, please take some time to get familiar with the game. You don't need to play it but please at least know the basic terminologies, like what is a Pal. (And also, if you do play it, please do not spend too much time on it.)\n",
    "\n",
    "The two recommended database is [https://palworld.gg/](https://palworld.gg/) and [https://paldb.cc/en/](https://paldb.cc/en/). You can use either, or both, or some other database about the Palworld. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part 1.1 (10 points)\n",
    "\n",
    "1. Are a Pal's work suitability scores (like Kindling, Planting, etc.) related to their elemental type? For example, do Fire-type Pals tend to have higher Kindling scores?\n",
    "\n",
    "2. Which features (like element type, size, rarity) may affect a Pal's base power level and stats (HP, Attack, etc.)?\n",
    "\n",
    "3. Based on work suitability scores and element types, which Pals are most similar in terms of their utility for base building and resource gathering?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part 1.2 (20 points)\n",
    "\n",
    "Based on the questions we proposed in the part 1.1, what features we may need to include in the analysis? Check the websites, which website has those information? **You need to pick at least 8 features for analysis.** We recommend a mix of numerical (numbers etc.) and categorical (level etc.) features. Is there any other features that you think it may be important but hard to extract or find on the website (can be something in or not in the game)?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Number of Work Suitabilities: The number of different work types a Pal can perform (e.g., 1, 2, 3). This measures versatility and can be correlated with rarity or element type to determine if more versatile Pals are also rarer or stronger.\n",
    "2. Pal ID Number: A numerical identifier for each Pal (e.g., #100). Useful for indexing and dataset integrity, though not for direct analysis.\n",
    "3. Element Type: The elemental type(s) of the Pal (e.g., Fire, Earth, Dark, etc.). This is crucial for understanding how elemental types relate to work suitability and combat stats.\n",
    "4. Rarity: The rarity tier of the Pal (e.g., Common, Rare, Epic, Legendary). Can be used to analyze trends in strength, utility, or drop rates.\n",
    "5. Work Suitability Types: The kinds of work the Pal is suitable for (e.g., Handiwork, Mining, Transporting). These can help us study which work categories are most associated with certain elements or rarities.\n",
    "6. Work Suitability Levels: Numerical levels indicating how effective a Pal is at a certain task (e.g., Lv 4 Handiwork). Useful for quantitative comparisons.\n",
    "7. HP: The base health points of the Pal. Important for combat-related analysis and can be compared against element types and rarity.\n",
    "8. Defense: The Pal’s defensive stat. Like HP, this can be used to explore if stronger defensive Pals trend toward certain types or rarities."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part 1.3 (20 points)\n",
    "\n",
    "Suppose you do have all the features you mentioned in part 1.2. List 3-4 data visulizations you can make with those features. You do not need to make those visulizations here. Just describe the type of the visualizations (histogram, scatter plot etc. ), which features are involved, will there any hover data or color being added, and **discuss how these data visualizations may be related (or even answer) to your questions in part 1.1**. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Scatter Plot – Work Suitability Level vs. HP\n",
    "- X-axis: Highest Work Suitability Level\n",
    "- Y-axis: HP\n",
    "- Color: Element Type\n",
    "- Hover Info: Pal ID, Rarity, Work Types\n",
    "- Why: To see if there’s a tradeoff between combat readiness (HP) and labor value (work level). Helps address question 1: Do elemental types affect work suitability scores?\n",
    "2. Grouped Bar Chart – Average Work Suitability Level by Element Type\n",
    "- X-axis: Element Types\n",
    "- Y-axis: Avg Work Level (split by work type: Mining, Transport, etc.)\n",
    "- Color: Work Type\n",
    "- Why: This directly addresses question 1 and 3 — seeing if, say, Fire-types are better at Kindling or if Water-types are better at Cooling.\n",
    "3. Heatmap – Rarity vs. Number of Work Suitabilities\n",
    "- Axes: Rarity (Y) × Number of Work Suitabilities (X)\n",
    "- Color: Frequency (how many Pals fall into each combination)\n",
    "- Why: Helps answer: Are rarer Pals more versatile? This addresses the updated feature 1 and part of question 2.\n",
    "4. Boxplot – HP and Defense Distribution by Rarity\n",
    "- X-axis: Rarity\n",
    "- Y-axis: HP or Defense\n",
    "- Color: Element Type (optional)\n",
    "- Why: To examine the relationship between rarity and battle strength. This supports question 2 — How do different features (like rarity or element) affect base stats?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part 1.4  (50 points)\n",
    "\n",
    "Now, go ahead and try to scrape the features you need. \n",
    "\n",
    "Please show all the codes you have for web scrapping. Your current output data frame should include at least 4 features. (You do not need to scrape all features at this moment, although it is recommend to start earlier. Also, you can choose to not to use the ones you have scraped in the later analysis. No need to worry if you need to change anything later). **Please design your code in pipeline and clearly document each function.** See the Python Style Guide in Week 1 for proper documentation. It is also recommended to save the data you have scrapped."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note: The above code is a template and you'll need to adjust the class names and HTML structure according to the actual website you're scraping (palworld.gg or paldb.cc). The key is to get data for all Pals at once to enable meaningful analysis later.\n"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# scrape palID\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import plotly.express as px\n",
    "\n",
    "def scrape_pal_ids(url = \"https://palworld.gg/pals\"):\n",
    "    \"\"\"\n",
    "    Scrape Pal IDs from the given URL.\n",
    "\n",
    "    Args:\n",
    "        url (str): The URL of the Palworld database page, assumed to be the current link unless otherwise specified.\n",
    "\n",
    "    Returns:\n",
    "        DataFrame: A dataFrame of Pal names and IDs.\n",
    "    \"\"\"\n",
    "    response = requests.get(url).text\n",
    "    soup = BeautifulSoup(response)\n",
    "\n",
    "    # Find all Pal ID elements\n",
    "    pal_dict = {}\n",
    "    for pal in soup.find_all(\"div\", class_ = \"pal\"):\n",
    "\n",
    "        # Remove empty Pal entries.\n",
    "        if pal.attrs[\"style\"] == \"display:none;\":\n",
    "            continue\n",
    "\n",
    "        # Get the ID and name of the Pal and add them to the dictionary.\n",
    "        pal_id_element = pal.find('span', class_='index').text.strip()\n",
    "        pal_dict[pal.find(\"div\", class_ = \"name\").next_element.strip()] = pal_id_element\n",
    "\n",
    "    # Convert the dictionary to a DataFrame before returning it.\n",
    "    return pd.DataFrame().from_dict(pal_dict, orient = \"index\", columns = [\"ID\"])\n",
    "\n",
    "pal_frame = scrape_pal_ids()\n",
    "pal_frame"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# Scrape the rarity of all the Pals\n",
    "def scrape_pal_rarity(pal_df, url = \"https://palworld.gg/pals\"):\n",
    "    \"\"\"\n",
    "    Scrape the rarity of each Pal listed in the database.\n",
    "\n",
    "    Args:\n",
    "        url (str): The URL of the database page, assumed to be the current link unless otherwise specified.\n",
    "        pal_df (DataFrame): The DataFrame of Pal data to update.\n",
    "\n",
    "    Returns:\n",
    "        pal_df (DataFrame): The DataFrame given, with the rarity of each Pal added under a new column.\n",
    "    \"\"\"\n",
    "    soup = BeautifulSoup(requests.get(url).text)\n",
    "\n",
    "    # Find all Pals, then find each of their rarities.\n",
    "    pal_tag = soup.find_all(\"div\", class_ = \"pal\")\n",
    "    for pal in pal_tag:\n",
    "\n",
    "        # Remove empty Pal entries.\n",
    "        if pal.attrs[\"style\"] == \"display:none;\":\n",
    "            continue\n",
    "\n",
    "        # The \"name\" class is used twice in each Pal entry, first for their name, then for their rarity.\n",
    "        name_class = pal.find_all(\"div\", class_ = \"name\")\n",
    "        # (Using next_element here rather than .text to avoid also getting the text from the nested children.)\n",
    "        # Add the rarity of the Pal to the DataFrame under its name.\n",
    "        pal_df.loc[name_class[0].next_element.strip(), \"Rarity\"] = name_class[1].next_element\n",
    "\n",
    "    return pal_df\n",
    "\n",
    "\n",
    "pal_frame = scrape_pal_rarity(pal_frame)\n",
    "pal_frame"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# Scrape the elements of the Pals\n",
    "def scrape_pal_elements(pal_df, url = \"https://palworld.gg/pals\"):\n",
    "    \"\"\"\n",
    "    Scrape the element or elements of each Pal listed in the database.\n",
    "\n",
    "    Args:\n",
    "        url (str): The URL of the database page, assumed to be the current link unless otherwise specified.\n",
    "        pal_df (DataFrame): The DataFrame of Pal data to update.\n",
    "\n",
    "    Returns:\n",
    "        pal_df (DataFrame): The DataFrame given, with a dummy variable added for each element,\n",
    "        True meaning that a Pal does belong to them and False for not.\n",
    "    \"\"\"\n",
    "    soup = BeautifulSoup(requests.get(url).text)\n",
    "\n",
    "    # Find each Pal entry.\n",
    "    pal_tag = soup.find_all(\"div\", class_ = \"pal\")\n",
    "    for pal in pal_tag:\n",
    "        # Remove empty Pal entries.\n",
    "        if pal.attrs[\"style\"] == \"display:none;\":\n",
    "            continue\n",
    "\n",
    "        # Load the individual entry page for the Pal.\n",
    "        pal_page = requests.get(\"https://palworld.gg\" + pal.a.attrs[\"href\"]).text\n",
    "        pal_soup = BeautifulSoup(pal_page)\n",
    "\n",
    "        # Scrape the Pal's name.\n",
    "        pal_name = pal_soup.find(\"h1\", class_ = \"name\").text.strip()\n",
    "\n",
    "        # Initialize all the element column values for this Pal to False, as none have been found yet.\n",
    "        pal_df.loc[pal_name, [\"Earth\", \"Fire\", \"Dragon\", \"Dark\", \"Electricity\", \"Water\", \"Ice\", \"Leaf\", \"Normal\"]] = False\n",
    "\n",
    "        # Scrape the elements of the Pal.\n",
    "        pal_elems_tags = pal_soup.find(\"div\", class_ = \"elements\").find_all(\"div\", class_ = \"name\")\n",
    "        for tag in pal_elems_tags:\n",
    "            # For each found element, change the Pal's value in the corresponding column to True.\n",
    "            pal_df.loc[pal_name, tag.text] = True\n",
    "        \n",
    "    return pal_df\n",
    "\n",
    "pal_frame = scrape_pal_elements(pal_frame)\n",
    "pal_frame"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# Create Element Type column from one-hot element columns\n",
    "element_cols = [\"Earth\", \"Fire\", \"Dragon\", \"Dark\", \"Electricity\", \"Water\", \"Ice\", \"Leaf\", \"Normal\"]\n",
    "\n",
    "def get_element_type(row):\n",
    "    for col in element_cols:\n",
    "        if col in row.index and row[col] > 0:\n",
    "            return col\n",
    "    return \"Unknown\"\n",
    "\n",
    "pal_frame[\"Element Type\"] = pal_frame.apply(get_element_type, axis=1)\n",
    "\n",
    "# Define fixed colors for each element\n",
    "element_colors = {\n",
    "    \"Earth\": \"#8B4513\",        # SaddleBrown\n",
    "    \"Fire\": \"#FF4500\",         # OrangeRed\n",
    "    \"Dragon\": \"#800080\",       # Purple\n",
    "    \"Dark\": \"#2F4F4F\",         # DarkSlateGray\n",
    "    \"Electricity\": \"#FFD700\",  # Gold\n",
    "    \"Water\": \"#1E90FF\",        # DodgerBlue\n",
    "    \"Ice\": \"#00CED1\",          # DarkTurquoise\n",
    "    \"Leaf\": \"#228B22\",         # ForestGreen\n",
    "    \"Normal\": \"#A9A9A9\",       # DarkGray\n",
    "    \"Unknown\": \"#808080\"       # Gray\n",
    "}"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# Scrape the work suitability of the Pals\n",
    "def scrape_pal_work(pal_df, url = \"https://palworld.gg/pals\"):\n",
    "    \"\"\"\n",
    "    Scrape the work suitabilities of each Pal listed in the database, including the level of each work type.\n",
    "\n",
    "    Args:\n",
    "        url (str): The URL of the database page, assumed to be the current link unless otherwise specified.\n",
    "        pal_df (DataFrame): The DataFrame of Pal data to update.\n",
    "\n",
    "    Returns:\n",
    "        pal_df (DataFrame): The DataFrame given, with 13 new columns added: 12 representing the work suitabilities\n",
    "        of Pals, each filled with NaN or the Pal's skill level for that task, and one column counting the number of suitabilities\n",
    "        the Pal has in total.\n",
    "    \"\"\"\n",
    "    soup = BeautifulSoup(requests.get(url).text)\n",
    "\n",
    "    # Find each Pal entry.\n",
    "    pal_tag = soup.find_all(\"div\", class_ = \"pal\")\n",
    "    for pal in pal_tag:\n",
    "        # Remove empty Pal entries.\n",
    "        if pal.attrs[\"style\"] == \"display:none;\":\n",
    "            continue\n",
    "\n",
    "        # Load the individual entry page for the Pal.\n",
    "        pal_page = requests.get(\"https://palworld.gg\" + pal.a.attrs[\"href\"]).text\n",
    "        pal_soup = BeautifulSoup(pal_page)\n",
    "\n",
    "        # Scrape the name of the Pal.\n",
    "        pal_name = pal_soup.find(\"h1\", class_ = \"name\").text.strip()\n",
    "\n",
    "        # Scrape the suitabilities of the Pal, and for each one that is found add its level to the column with the suitability's name.\n",
    "        pal_work_tags = pal_soup.find(\"div\", class_ = \"works\").find_all(\"div\", class_ = \"active item\")\n",
    "        for tag in pal_work_tags:\n",
    "            pal_df.loc[pal_name, tag.find(\"div\", class_ = \"name\").text] = tag.find(\"span\", class_ = \"value\").text\n",
    "        # Add the pal's total number of suitabilities as a new column.\n",
    "        pal_df.loc[pal_name, \"Number of work suitabilities\"] = len(pal_work_tags)\n",
    "        \n",
    "    return pal_df\n",
    "\n",
    "pal_frame = scrape_pal_work(pal_frame)\n",
    "pal_frame"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# Scrape the HP of the Pals\n",
    "def scrape_pal_hp(pal_df, url = \"https://palworld.gg/pals\"):\n",
    "    \"\"\"\n",
    "    Scrape the HP of each Pal listed in the database.\n",
    "\n",
    "    Args:\n",
    "        url (str): The URL of the database page, assumed to be the current link unless otherwise specified.\n",
    "        pal_df (DataFrame): The DataFrame of Pal data to update.\n",
    "\n",
    "    Returns:\n",
    "        pal_df (DataFrame): The DataFrame given, with a new column representing the Pals' HPs.\n",
    "    \"\"\"\n",
    "    soup = BeautifulSoup(requests.get(url).text)\n",
    "\n",
    "    # Find each Pal entry.\n",
    "    pal_tag = soup.find_all(\"div\", class_ = \"pal\")\n",
    "    for pal in pal_tag:\n",
    "        # Remove empty Pal entries.\n",
    "        if pal.attrs[\"style\"] == \"display:none;\":\n",
    "            continue\n",
    "\n",
    "        # Load the individual entry page for the Pal.\n",
    "        pal_page = requests.get(\"https://palworld.gg\" + pal.a.attrs[\"href\"]).text\n",
    "        pal_soup = BeautifulSoup(pal_page)\n",
    "\n",
    "        # Scrape the name of the Pal.\n",
    "        pal_name = pal_soup.find(\"h1\", class_ = \"name\").text.strip()\n",
    "\n",
    "        # Scrape the HP of the pal (the first entry in the stats section) and add it to the HP column.\n",
    "        pal_hp = int(pal_soup.find(\"div\", class_ = \"stats\").find_all(\"div\", class_ = \"value\")[0].text)\n",
    "        pal_df.loc[pal_name, \"HP\"] = pal_hp\n",
    "        \n",
    "    return pal_df\n",
    "\n",
    "pal_frame = scrape_pal_hp(pal_frame)\n",
    "pal_frame"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# Scrape the defense statistics of the Pals\n",
    "def scrape_pal_defense(pal_df, url = \"https://palworld.gg/pals\"):\n",
    "    \"\"\"\n",
    "    Scrape the defense score of each Pal listed in the database.\n",
    "\n",
    "    Args:\n",
    "        url (str): The URL of the database page, assumed to be the current link unless otherwise specified.\n",
    "        pal_df (DataFrame): The DataFrame of Pal data to update.\n",
    "\n",
    "    Returns:\n",
    "        pal_df (DataFrame): The DataFrame given, with a new column representing the Pals' defense scores.\n",
    "    \"\"\"\n",
    "    soup = BeautifulSoup(requests.get(url).text)\n",
    "\n",
    "    # Find each Pal entry.\n",
    "    pal_tag = soup.find_all(\"div\", class_ = \"pal\")\n",
    "    for pal in pal_tag:\n",
    "        # Remove empty Pal entries.\n",
    "        if pal.attrs[\"style\"] == \"display:none;\":\n",
    "            continue\n",
    "\n",
    "        # Load the individual entry page for the Pal.\n",
    "        pal_page = requests.get(\"https://palworld.gg\" + pal.a.attrs[\"href\"]).text\n",
    "        pal_soup = BeautifulSoup(pal_page)\n",
    "\n",
    "        # Scrape the name of the Pal.\n",
    "        pal_name = pal_soup.find(\"h1\", class_ = \"name\").text.strip()\n",
    "\n",
    "        # Scrape the defense of the pal (the second entry in the stats section) and add it to the defense column.\n",
    "        pal_hp = int(pal_soup.find(\"div\", class_ = \"stats\").find_all(\"div\", class_ = \"value\")[1].text)\n",
    "        pal_df.loc[pal_name, \"Defense\"] = pal_hp\n",
    "        \n",
    "    return pal_df\n",
    "\n",
    "pal_frame = scrape_pal_defense(pal_frame)\n",
    "pal_frame"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# todo: start visualizing the data in graphs and plotting fits for relationships\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# just a little graph for fun\n",
    "plt.scatter(x = pal_frame[\"HP\"], y = pal_frame[\"Defense\"])"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "import pandas as pd\n",
    "import plotly.express as px\n",
    "\n",
    "\n",
    "# --- Detect work-type columns ---\n",
    "work_list = ['Handiwork', 'Mining',\n",
    "       'Transporting', 'Deforesting',\n",
    "       'Kindling', 'Gathering', 'Generating Electricity', 'Watering',\n",
    "       'Cooling', 'Farming', 'Medicine Production', 'Planting']\n",
    "work_columns = pal_frame[work_list]\n",
    "\n",
    "\n",
    "def build_features(df, work_cols):\n",
    "    out = df.copy()\n",
    "    for idx in range(len(work_cols)):\n",
    "        pal = work_cols.iloc[idx, :]\n",
    "        pal = pal.dropna()\n",
    "        out.loc[pal.name, \"Highest Work Suitability Level\"] = pal.sort_values(ascending = False).iloc[0]\n",
    "        out.loc[pal.name, \"Work Types\"] = \", \".join(pal.index)\n",
    "        out.loc[pal.name, \"Work Skill Count\"] = len(pal.index)\n",
    "\n",
    "    return out\n",
    "\n",
    "# --- Prepare data ---\n",
    "pal_frame_vis = build_features(pal_frame, work_columns)\n",
    "\n",
    "# --- 1. Scatter Plot ---\n",
    "fig1 = px.scatter(\n",
    "    pal_frame_vis.sort_values(by = \"Highest Work Suitability Level\", ascending = True),\n",
    "    x=\"Highest Work Suitability Level\",\n",
    "    y=\"HP\",\n",
    "    color=\"Element Type\",\n",
    "    hover_data={\"ID\":True, \"Rarity\":True, \"Work Types\":True},\n",
    "    title=\"Work Suitability vs HP by Element Type\"\n",
    ")\n",
    "fig1.show()\n",
    "\n",
    "# --- 2. Grouped Bar Chart ---\n",
    "melted = pal_frame_vis.melt(\n",
    "    id_vars=[\"Element Type\"],\n",
    "    value_vars=work_columns,\n",
    "    var_name=\"Work Type\",\n",
    "    value_name=\"Level\"\n",
    ")\n",
    "melted[\"Level\"] = pd.to_numeric(melted[\"Level\"], errors=\"coerce\")\n",
    "melted = melted.dropna(subset=[\"Level\"])\n",
    "    \n",
    "agg_df = (melted.groupby([\"Element Type\", \"Work Type\"], as_index=False, observed=True)\n",
    "          .agg(Level=(\"Level\", \"mean\")))\n",
    "    \n",
    "fig2 = px.bar(\n",
    "    agg_df,\n",
    "    x=\"Element Type\", y=\"Level\", color=\"Work Type\",\n",
    "    barmode=\"group\",\n",
    "    title=\"Average Work Suitability Level by Element Type & Work Type\"\n",
    ")\n",
    "fig2.show()\n",
    "\n",
    "\n",
    "# --- 3. Heatmap ---\n",
    "heat_df = pal_frame_vis.groupby([\"Rarity\",\"Work Skill Count\"]).size().reset_index(name=\"Count\")\n",
    "fig3 = px.density_heatmap(\n",
    "    heat_df,\n",
    "    x=\"Work Skill Count\", y=\"Rarity\", z=\"Count\", color_continuous_scale=\"Viridis\",\n",
    "    title=\"Rarity vs. Number of Work Suitabilities (Frequency)\"\n",
    ")\n",
    "fig3.show()\n",
    "\n",
    "# --- 4. Boxplots ---\n",
    "fig4 = px.box(pal_frame_vis, x=\"Rarity\", y=\"HP\", color=\"Element Type\",\n",
    "              title=\"HP Distribution by Rarity\")\n",
    "fig4.show()\n",
    "fig5 = px.box(pal_frame_vis, x=\"Rarity\", y=\"Defense\", color=\"Element Type\",\n",
    "              title=\"Defense Distribution by Rarity\")\n",
    "fig5.show()\n"
   ],
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
