{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is the template for DS3000 Final data analysis project. Once you finish, please remove all my instructions. You do not need to exactly follow the structure in the template but please make sure you have all the components. Write your report in paragraphs. Only use bullet points when list something (eg: functions) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Investigating Palworld Through Data Analysis\n",
    "#### Team 11\n",
    "- Ansh Aggarwal\n",
    "- Sohum Balsara\n",
    "- Bear Smith"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# imports\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import plotly.express as px"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduction\n",
    "\n",
    "In this project we study Palworld, a survival and monster-taming video game in which players collect characters called Pals to battle each other and help build their bases. Each Pal has a different set of skills and qualifications, a combination of such features as their element type, their HP in battle, and their \"work suitability\" for various tasks like farming or electricity production. We want to learn about how those factors combine and influence each other, and what relationships that may not be stated outwardly can be found between them. This may help players better understand their game and be more successful at it, or at least increase their knowledge of the logic behind Palworld.\n",
    "\n",
    "Our primary research questions are:\n",
    "- How are a Pal's work suitability scores correlated to its other statistics, such as its element type or battle skills?\n",
    "- What relationship does Pal rarity have with their other statistics?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data \n",
    "\n",
    "### Data Source\n",
    "\n",
    "- All data was taken from [palworld.gg](\"https://palworld.gg\").\n",
    "- We scraped each Pal's name, ID number, rarity, element(s), work suitability type(s) and level(s), HP, and defense scores.\n",
    "- To make the data frame more easily filtered, the Pals' elements were listed using multiple boolean columns, each representing one element.\n",
    "- For that same reason, their work suitabilities were also listed by column, but instead of True or False, each value was the Pal's level in that suitability or Nan if they did not have it. That way, dropna can be used to filter the data frame by element type.\n",
    "- Finally, the Pals' HP and defense stats were converted to numbers in the data frame, so that mathematical operations can be done on those columns.\n",
    "\n",
    "### Webscraping and cleaning functions overview\n",
    "- `scrape_pal_ids()`\n",
    "    - Creates a data frame with all the Pals' names as its index and one column of data containing their IDs.\n",
    "- `scrape_pal_rarity()`\n",
    "    - Adds a column containing the rarity of each Pal to the given data frame.\n",
    "- `scrape_pal_elements()`\n",
    "    - Adds the element or elements of each Pal to the given data frame using one-hot columns.\n",
    "- `scrape_pal_work()`\n",
    "    - Adds the work suitability or suitabilities of each Pal to the given data frame, along with its level.\n",
    "- `scrape_pal_hp()`\n",
    "    - Adds a column containing the HP of each Pal to the given data frame.\n",
    "- `scrape_pal_defense()`\n",
    "    - Adds a column containing the defense score of each Pal to the given data frame.\n",
    "\n",
    "### Data overview\n",
    "\n",
    "# TODO - IN PROGRESS\n",
    "- You can see a couple rows of our data below.\n",
    "- We store the Pals' rarity, their element or elements, their work suitabilities and what levels they are, \n",
    "- Discuss if there is any potential problems about the data (eg: missing values, any features that you did not collect but may be important, any other concerns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>Rarity</th>\n",
       "      <th>Earth</th>\n",
       "      <th>Fire</th>\n",
       "      <th>Dragon</th>\n",
       "      <th>Dark</th>\n",
       "      <th>Electricity</th>\n",
       "      <th>Water</th>\n",
       "      <th>Ice</th>\n",
       "      <th>Leaf</th>\n",
       "      <th>...</th>\n",
       "      <th>Kindling</th>\n",
       "      <th>Gathering</th>\n",
       "      <th>Generating Electricity</th>\n",
       "      <th>Watering</th>\n",
       "      <th>Cooling</th>\n",
       "      <th>Farming</th>\n",
       "      <th>Medicine Production</th>\n",
       "      <th>Planting</th>\n",
       "      <th>HP</th>\n",
       "      <th>Defense</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Anubis</th>\n",
       "      <td>#100</td>\n",
       "      <td>Epic</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>120</td>\n",
       "      <td>100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Arsox</th>\n",
       "      <td>#42</td>\n",
       "      <td>Common</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>2.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>85</td>\n",
       "      <td>95</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Astegon</th>\n",
       "      <td>#98</td>\n",
       "      <td>Epic</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>100</td>\n",
       "      <td>125</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Azurmane</th>\n",
       "      <td>#136</td>\n",
       "      <td>Rare</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>130</td>\n",
       "      <td>110</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Azurobe</th>\n",
       "      <td>#82</td>\n",
       "      <td>Rare</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>110</td>\n",
       "      <td>100</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 26 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            ID  Rarity  Earth   Fire  Dragon   Dark  Electricity  Water  \\\n",
       "Anubis    #100    Epic   True  False   False  False        False  False   \n",
       "Arsox      #42  Common  False   True   False  False        False  False   \n",
       "Astegon    #98    Epic  False  False    True   True        False  False   \n",
       "Azurmane  #136    Rare  False  False   False  False         True  False   \n",
       "Azurobe    #82    Rare  False  False    True  False        False   True   \n",
       "\n",
       "            Ice   Leaf  ...  Kindling  Gathering  Generating Electricity  \\\n",
       "Anubis    False  False  ...       NaN        NaN                     NaN   \n",
       "Arsox     False  False  ...       2.0        NaN                     NaN   \n",
       "Astegon   False  False  ...       NaN        NaN                     NaN   \n",
       "Azurmane  False  False  ...       NaN        1.0                     4.0   \n",
       "Azurobe   False  False  ...       NaN        NaN                     NaN   \n",
       "\n",
       "          Watering  Cooling  Farming  Medicine Production  Planting   HP  \\\n",
       "Anubis         NaN      NaN      NaN                  NaN       NaN  120   \n",
       "Arsox          NaN      NaN      NaN                  NaN       NaN   85   \n",
       "Astegon        NaN      NaN      NaN                  NaN       NaN  100   \n",
       "Azurmane       NaN      NaN      NaN                  NaN       NaN  130   \n",
       "Azurobe        3.0      NaN      NaN                  NaN       NaN  110   \n",
       "\n",
       "          Defense  \n",
       "Anubis        100  \n",
       "Arsox          95  \n",
       "Astegon       125  \n",
       "Azurmane      110  \n",
       "Azurobe       100  \n",
       "\n",
       "[5 rows x 26 columns]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "pal_frame = pd.read_excel(\"pal_frame_for_project.xlsx\")\n",
    "# Reset the index back to the Pal names after reading in the spreadsheet file.\n",
    "pal_frame.set_index(\"Unnamed: 0\", inplace = True)\n",
    "pal_frame.rename_axis(None, axis = 0, inplace = True)\n",
    "pal_frame.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Webscraping and cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# list all the functions you have for webscraping and cleaning. Make sure write full \n",
    "# docstrings for each function\n",
    "\n",
    "def scrape_pal_ids(url = \"https://palworld.gg/pals\"):\n",
    "    \"\"\"\n",
    "    Scrape Pal IDs from the given URL.\n",
    "\n",
    "    Args:\n",
    "        url (str): The URL of the Palworld database page, assumed to be the current link unless otherwise specified.\n",
    "\n",
    "    Returns:\n",
    "        DataFrame: A dataFrame of Pal names and IDs.\n",
    "    \"\"\"\n",
    "    response = requests.get(url).text\n",
    "    soup = BeautifulSoup(response)\n",
    "\n",
    "    # Find all Pal ID elements\n",
    "    pal_dict = {}\n",
    "    for pal in soup.find_all(\"div\", class_ = \"pal\"):\n",
    "\n",
    "        # Remove empty Pal entries.\n",
    "        if pal.attrs[\"style\"] == \"display:none;\":\n",
    "            continue\n",
    "\n",
    "        # Get the ID and name of the Pal and add them to the dictionary.\n",
    "        pal_id_element = pal.find('span', class_='index').text.strip()\n",
    "        pal_dict[pal.find(\"div\", class_ = \"name\").next_element.strip()] = pal_id_element\n",
    "\n",
    "    # Convert the dictionary to a DataFrame before returning it.\n",
    "    return pd.DataFrame().from_dict(pal_dict, orient = \"index\", columns = [\"ID\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def scrape_pal_rarity(pal_df, url = \"https://palworld.gg/pals\"):\n",
    "    \"\"\"\n",
    "    Scrape the rarity of each Pal listed in the database.\n",
    "\n",
    "    Args:\n",
    "        url (str): The URL of the database page, assumed to be the current link unless otherwise specified.\n",
    "        pal_df (DataFrame): The DataFrame of Pal data to update.\n",
    "\n",
    "    Returns:\n",
    "        pal_df (DataFrame): The DataFrame given, with the rarity of each Pal added under a new column.\n",
    "    \"\"\"\n",
    "    soup = BeautifulSoup(requests.get(url).text)\n",
    "\n",
    "    # Find all Pals, then find each of their rarities.\n",
    "    pal_tag = soup.find_all(\"div\", class_ = \"pal\")\n",
    "    for pal in pal_tag:\n",
    "\n",
    "        # Remove empty Pal entries.\n",
    "        if pal.attrs[\"style\"] == \"display:none;\":\n",
    "            continue\n",
    "\n",
    "        # The \"name\" class is used twice in each Pal entry, first for their name, then for their rarity.\n",
    "        name_class = pal.find_all(\"div\", class_ = \"name\")\n",
    "        # (Using next_element here rather than .text to avoid also getting the text from the nested children.)\n",
    "        # Add the rarity of the Pal to the DataFrame under its name.\n",
    "        pal_df.loc[name_class[0].next_element.strip(), \"Rarity\"] = name_class[1].next_element\n",
    "\n",
    "    return pal_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def scrape_pal_elements(pal_df, url = \"https://palworld.gg/pals\"):\n",
    "    \"\"\"\n",
    "    Scrape the element or elements of each Pal listed in the database.\n",
    "\n",
    "    Args:\n",
    "        url (str): The URL of the database page, assumed to be the current link unless otherwise specified.\n",
    "        pal_df (DataFrame): The DataFrame of Pal data to update.\n",
    "\n",
    "    Returns:\n",
    "        pal_df (DataFrame): The DataFrame given, with a dummy variable added for each element,\n",
    "        True meaning that a Pal does belong to them and False for not.\n",
    "    \"\"\"\n",
    "    soup = BeautifulSoup(requests.get(url).text)\n",
    "\n",
    "    # Find each Pal entry.\n",
    "    pal_tag = soup.find_all(\"div\", class_ = \"pal\")\n",
    "    for pal in pal_tag:\n",
    "        # Remove empty Pal entries.\n",
    "        if pal.attrs[\"style\"] == \"display:none;\":\n",
    "            continue\n",
    "\n",
    "        # Load the individual entry page for the Pal.\n",
    "        pal_page = requests.get(\"https://palworld.gg\" + pal.a.attrs[\"href\"]).text\n",
    "        pal_soup = BeautifulSoup(pal_page)\n",
    "\n",
    "        # Scrape the Pal's name.\n",
    "        pal_name = pal_soup.find(\"h1\", class_ = \"name\").text.strip()\n",
    "\n",
    "        # Initialize all the element column values for this Pal to False, as none have been found yet.\n",
    "        pal_df.loc[pal_name, [\"Earth\", \"Fire\", \"Dragon\", \"Dark\", \"Electricity\", \"Water\", \"Ice\", \"Leaf\", \"Normal\"]] = False\n",
    "\n",
    "        # Scrape the elements of the Pal.\n",
    "        pal_elems_tags = pal_soup.find(\"div\", class_ = \"elements\").find_all(\"div\", class_ = \"name\")\n",
    "        for tag in pal_elems_tags:\n",
    "            # For each found element, change the Pal's value in the corresponding column to True.\n",
    "            pal_df.loc[pal_name, tag.text] = True\n",
    "        \n",
    "    return pal_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def scrape_pal_work(pal_df, url = \"https://palworld.gg/pals\"):\n",
    "    \"\"\"\n",
    "    Scrape the work suitabilities of each Pal listed in the database, including the level of each work type.\n",
    "\n",
    "    Args:\n",
    "        url (str): The URL of the database page, assumed to be the current link unless otherwise specified.\n",
    "        pal_df (DataFrame): The DataFrame of Pal data to update.\n",
    "\n",
    "    Returns:\n",
    "        pal_df (DataFrame): The DataFrame given, with 13 new columns added: 12 representing the work suitabilities\n",
    "        of Pals, each filled with NaN or the Pal's skill level for that task, and one column counting the number of suitabilities\n",
    "        the Pal has in total.\n",
    "    \"\"\"\n",
    "    soup = BeautifulSoup(requests.get(url).text)\n",
    "\n",
    "    # Find each Pal entry.\n",
    "    pal_tag = soup.find_all(\"div\", class_ = \"pal\")\n",
    "    for pal in pal_tag:\n",
    "        # Remove empty Pal entries.\n",
    "        if pal.attrs[\"style\"] == \"display:none;\":\n",
    "            continue\n",
    "\n",
    "        # Load the individual entry page for the Pal.\n",
    "        pal_page = requests.get(\"https://palworld.gg\" + pal.a.attrs[\"href\"]).text\n",
    "        pal_soup = BeautifulSoup(pal_page)\n",
    "\n",
    "        # Scrape the name of the Pal.\n",
    "        pal_name = pal_soup.find(\"h1\", class_ = \"name\").text.strip()\n",
    "\n",
    "        # Scrape the suitabilities of the Pal, and for each one that is found add its level to the column with the suitability's name.\n",
    "        pal_work_tags = pal_soup.find(\"div\", class_ = \"works\").find_all(\"div\", class_ = \"active item\")\n",
    "        for tag in pal_work_tags:\n",
    "            pal_df.loc[pal_name, tag.find(\"div\", class_ = \"name\").text] = tag.find(\"span\", class_ = \"value\").text\n",
    "        # Add the pal's total number of suitabilities as a new column.\n",
    "        pal_df.loc[pal_name, \"Number of work suitabilities\"] = len(pal_work_tags)\n",
    "        \n",
    "    return pal_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def scrape_pal_hp(pal_df, url = \"https://palworld.gg/pals\"):\n",
    "    \"\"\"\n",
    "    Scrape the HP of each Pal listed in the database.\n",
    "\n",
    "    Args:\n",
    "        url (str): The URL of the database page, assumed to be the current link unless otherwise specified.\n",
    "        pal_df (DataFrame): The DataFrame of Pal data to update.\n",
    "\n",
    "    Returns:\n",
    "        pal_df (DataFrame): The DataFrame given, with a new column representing the Pals' HPs.\n",
    "    \"\"\"\n",
    "    soup = BeautifulSoup(requests.get(url).text)\n",
    "\n",
    "    # Find each Pal entry.\n",
    "    pal_tag = soup.find_all(\"div\", class_ = \"pal\")\n",
    "    for pal in pal_tag:\n",
    "        # Remove empty Pal entries.\n",
    "        if pal.attrs[\"style\"] == \"display:none;\":\n",
    "            continue\n",
    "\n",
    "        # Load the individual entry page for the Pal.\n",
    "        pal_page = requests.get(\"https://palworld.gg\" + pal.a.attrs[\"href\"]).text\n",
    "        pal_soup = BeautifulSoup(pal_page)\n",
    "\n",
    "        # Scrape the name of the Pal.\n",
    "        pal_name = pal_soup.find(\"h1\", class_ = \"name\").text.strip()\n",
    "\n",
    "        # Scrape the HP of the pal (the first entry in the stats section) and add it to the HP column.\n",
    "        pal_hp = int(pal_soup.find(\"div\", class_ = \"stats\").find_all(\"div\", class_ = \"value\")[0].text)\n",
    "        pal_df.loc[pal_name, \"HP\"] = pal_hp\n",
    "        \n",
    "    return pal_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def scrape_pal_defense(pal_df, url = \"https://palworld.gg/pals\"):\n",
    "    \"\"\"\n",
    "    Scrape the defense score of each Pal listed in the database.\n",
    "\n",
    "    Args:\n",
    "        url (str): The URL of the database page, assumed to be the current link unless otherwise specified.\n",
    "        pal_df (DataFrame): The DataFrame of Pal data to update.\n",
    "\n",
    "    Returns:\n",
    "        pal_df (DataFrame): The DataFrame given, with a new column representing the Pals' defense scores.\n",
    "    \"\"\"\n",
    "    soup = BeautifulSoup(requests.get(url).text)\n",
    "\n",
    "    # Find each Pal entry.\n",
    "    pal_tag = soup.find_all(\"div\", class_ = \"pal\")\n",
    "    for pal in pal_tag:\n",
    "        # Remove empty Pal entries.\n",
    "        if pal.attrs[\"style\"] == \"display:none;\":\n",
    "            continue\n",
    "\n",
    "        # Load the individual entry page for the Pal.\n",
    "        pal_page = requests.get(\"https://palworld.gg\" + pal.a.attrs[\"href\"]).text\n",
    "        pal_soup = BeautifulSoup(pal_page)\n",
    "\n",
    "        # Scrape the name of the Pal.\n",
    "        pal_name = pal_soup.find(\"h1\", class_ = \"name\").text.strip()\n",
    "\n",
    "        # Scrape the defense of the pal (the second entry in the stats section) and add it to the defense column.\n",
    "        pal_hp = int(pal_soup.find(\"div\", class_ = \"stats\").find_all(\"div\", class_ = \"value\")[1].text)\n",
    "        pal_df.loc[pal_name, \"Defense\"] = pal_hp\n",
    "        \n",
    "    return pal_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>Rarity</th>\n",
       "      <th>Earth</th>\n",
       "      <th>Fire</th>\n",
       "      <th>Dragon</th>\n",
       "      <th>Dark</th>\n",
       "      <th>Electricity</th>\n",
       "      <th>Water</th>\n",
       "      <th>Ice</th>\n",
       "      <th>Leaf</th>\n",
       "      <th>...</th>\n",
       "      <th>Kindling</th>\n",
       "      <th>Gathering</th>\n",
       "      <th>Generating Electricity</th>\n",
       "      <th>Watering</th>\n",
       "      <th>Cooling</th>\n",
       "      <th>Farming</th>\n",
       "      <th>Medicine Production</th>\n",
       "      <th>Planting</th>\n",
       "      <th>HP</th>\n",
       "      <th>Defense</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Anubis</th>\n",
       "      <td>#100</td>\n",
       "      <td>Epic</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>120.0</td>\n",
       "      <td>100.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Arsox</th>\n",
       "      <td>#42</td>\n",
       "      <td>Common</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>85.0</td>\n",
       "      <td>95.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Astegon</th>\n",
       "      <td>#98</td>\n",
       "      <td>Epic</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>100.0</td>\n",
       "      <td>125.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Azurmane</th>\n",
       "      <td>#136</td>\n",
       "      <td>Rare</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>130.0</td>\n",
       "      <td>110.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Azurobe</th>\n",
       "      <td>#82</td>\n",
       "      <td>Rare</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>110.0</td>\n",
       "      <td>100.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Wumpo Botan</th>\n",
       "      <td>#91</td>\n",
       "      <td>Epic</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>140.0</td>\n",
       "      <td>110.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Xenogard</th>\n",
       "      <td>#126</td>\n",
       "      <td>Epic</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>110.0</td>\n",
       "      <td>130.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Xenolord</th>\n",
       "      <td>#127</td>\n",
       "      <td>Epic</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>130.0</td>\n",
       "      <td>120.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Xenovader</th>\n",
       "      <td>#125</td>\n",
       "      <td>Rare</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>90.0</td>\n",
       "      <td>85.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Yakumo</th>\n",
       "      <td>#121</td>\n",
       "      <td>Common</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>85.0</td>\n",
       "      <td>85.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>225 rows Ã— 26 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "               ID  Rarity  Earth   Fire Dragon   Dark Electricity  Water  \\\n",
       "Anubis       #100    Epic   True  False  False  False       False  False   \n",
       "Arsox         #42  Common  False   True  False  False       False  False   \n",
       "Astegon       #98    Epic  False  False   True   True       False  False   \n",
       "Azurmane     #136    Rare  False  False  False  False        True  False   \n",
       "Azurobe       #82    Rare  False  False   True  False       False   True   \n",
       "...           ...     ...    ...    ...    ...    ...         ...    ...   \n",
       "Wumpo Botan   #91    Epic  False  False  False  False       False  False   \n",
       "Xenogard     #126    Epic  False  False   True  False       False  False   \n",
       "Xenolord     #127    Epic  False  False   True   True       False  False   \n",
       "Xenovader    #125    Rare  False  False  False   True       False  False   \n",
       "Yakumo       #121  Common  False  False  False  False       False  False   \n",
       "\n",
       "               Ice   Leaf  ... Kindling Gathering Generating Electricity  \\\n",
       "Anubis       False  False  ...      NaN       NaN                    NaN   \n",
       "Arsox        False  False  ...        2       NaN                    NaN   \n",
       "Astegon      False  False  ...      NaN       NaN                    NaN   \n",
       "Azurmane     False  False  ...      NaN         1                      4   \n",
       "Azurobe      False  False  ...      NaN       NaN                    NaN   \n",
       "...            ...    ...  ...      ...       ...                    ...   \n",
       "Wumpo Botan  False   True  ...      NaN       NaN                    NaN   \n",
       "Xenogard     False  False  ...      NaN       NaN                    NaN   \n",
       "Xenolord     False  False  ...      NaN         1                    NaN   \n",
       "Xenovader    False  False  ...      NaN       NaN                    NaN   \n",
       "Yakumo       False  False  ...      NaN         2                    NaN   \n",
       "\n",
       "            Watering  Cooling Farming Medicine Production Planting     HP  \\\n",
       "Anubis           NaN      NaN     NaN                 NaN      NaN  120.0   \n",
       "Arsox            NaN      NaN     NaN                 NaN      NaN   85.0   \n",
       "Astegon          NaN      NaN     NaN                 NaN      NaN  100.0   \n",
       "Azurmane         NaN      NaN     NaN                 NaN      NaN  130.0   \n",
       "Azurobe            3      NaN     NaN                 NaN      NaN  110.0   \n",
       "...              ...      ...     ...                 ...      ...    ...   \n",
       "Wumpo Botan      NaN      NaN     NaN                 NaN        1  140.0   \n",
       "Xenogard         NaN      NaN     NaN                 NaN      NaN  110.0   \n",
       "Xenolord         NaN      NaN     NaN                 NaN      NaN  130.0   \n",
       "Xenovader        NaN      NaN     NaN                 NaN      NaN   90.0   \n",
       "Yakumo           NaN      NaN     NaN                 NaN      NaN   85.0   \n",
       "\n",
       "            Defense  \n",
       "Anubis        100.0  \n",
       "Arsox          95.0  \n",
       "Astegon       125.0  \n",
       "Azurmane      110.0  \n",
       "Azurobe       100.0  \n",
       "...             ...  \n",
       "Wumpo Botan   110.0  \n",
       "Xenogard      130.0  \n",
       "Xenolord      120.0  \n",
       "Xenovader      85.0  \n",
       "Yakumo         85.0  \n",
       "\n",
       "[225 rows x 26 columns]"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pal_df = scrape_pal_defense(scrape_pal_hp(scrape_pal_work(scrape_pal_elements(scrape_pal_rarity(scrape_pal_ids())))))\n",
    "pal_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualizations\n",
    "\n",
    "### Visualization functions overview\n",
    "List all the functions you have written for visualization. For each one, write one sentence to describe it. \n",
    "- `make_hist()`\n",
    "    - Generate a histogram with given data and feature\n",
    " \n",
    "### Visualization results\n",
    "- Present 3-4 data visualizations.\n",
    "- For each visualization, you need to include title, xlabel, ylabel, legend (if necessary)\n",
    "- For each visualization, explain why you make this data visualization (how it related to your research question) and explain what you have learned from this visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# list all the functions you have for visualization. Make sure write full \n",
    "# docstrings for each function\n",
    "def make_hist(df, y_feat):\n",
    "\n",
    "    pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### visualization 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write the code to run functions to get each data visualization in separate code chunks. \n",
    "# Interpret the figures. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### visualization 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write the code to run functions to get each data visualization in separate code chunks. \n",
    "# Interpret the figures. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### visualization 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write the code to run functions to get each data visualization in separate code chunks. \n",
    "# Interpret the figures. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Models\n",
    "\n",
    "### Modeling functions overview\n",
    "List all the functions you have written for modeling. For each one, write one sentence to describe it. \n",
    "- `fit_linear()`\n",
    "    - fit a linear model to the data and output the r2, slope and intercept\n",
    "\n",
    "### Model results\n",
    "\n",
    "- Present 2-3 models for the analysis.\n",
    "- Explain any pre-processing steps you have done (eg: scaling, polynomial, dummy features)\n",
    "- For each model, explain why you think this model is suitable and what metrics you want to use to evaluate the model\n",
    "    - If it is a classification model, you need to present the confusion matrix, calculate the accuracy, sensitivity and specificity with cross-validation\n",
    "    - If it is a regression model, you need to present the r2 and MSE with cross-validation\n",
    "    - If it is a linear regression model/multiple linear regression model, you need to interpret the meaning of the coefficient with the full data\n",
    "    - If it is a decision tree model, you need to plot the tree with the full data\n",
    "    - If it is a random forest model, you need to present the feature importance plot with the full data\n",
    "    - If it is a PCA, you need to explain how to select the number of components and interpret the key features in the first two components\n",
    "    - If it is a clustering, you need explain how to select the number of clustering and summarize the clustering. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# list all the functions you have for modeling. Make sure write full \n",
    "# docstrings for each function\n",
    "def fit_linear(df, y_feat, x_feat):\n",
    "\n",
    "    pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Model 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write the code to run functions to fit each model in separate code chunks. \n",
    "# Interpret the model results. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Model 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write the code to run functions to fit each model in separate code chunks. \n",
    "# Interpret the model results. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Model 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write the code to run functions to fit each model in separate code chunks. \n",
    "# Interpret the model results. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Discussion\n",
    "\n",
    "- One or two paragraphs to summarize your findings in the modeling sections and do the models answer your research question?\n",
    "- Any other potential thing you can do with the analysis (eg: include more features, get more data, try some other models etc.)\n",
    "- List the contribution for each group member.\n",
    "\n",
    "### Contributions\n",
    "- Sohum came up with the majority of our research questions and visualization ideas.\n",
    "- Bear wrote the web scraping functions.\n",
    "- Ansh wrote the data visualizations.\n",
    "- "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
